{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import math\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve,precision_recall_fscore_support\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Entire Dataset (memory issues possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train\n",
    "filename = \"X_train.pkl\"\n",
    "X_train_all = pd.read_pickle(filename)#, skiprows=skip, sep='\\t',index_col=0)\n",
    "\n",
    "#X_test\n",
    "filename = \"X_test.pkl\"\n",
    "X_test_all = pd.read_pickle(filename)#, skiprows=skip, sep='\\t',index_col=0)\n",
    "\n",
    "#y_train\n",
    "filename = \"y_train.pkl\"\n",
    "y_train_all = pd.read_pickle(filename)#, skiprows=skip, sep='\\t',index_col=0)\n",
    "\n",
    "#y_test\n",
    "filename = \"y_test.pkl\"\n",
    "y_test_all = pd.read_pickle(filename)#, skiprows=skip, sep='\\t',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(880950, 1133)\n",
      "(377551, 1133)\n",
      "(880950, 1)\n",
      "(377551, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_all.shape)\n",
    "print(X_test_all.shape)\n",
    "print(y_train_all.shape)\n",
    "print(y_test_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop non-numeric columns to prepare for classification model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop OHE source columns & unuseful categorical variables\n",
    "X_train_all.drop(columns=['term','verification_status',\n",
    "                          'grade','emp_title', 'addr_state',\n",
    "                          #ALSO, drop redundant columns that new OHE columns provide the info for\n",
    "                          'debt_settlement_flag',#ALSO, drop columns clearly not predictive of class\n",
    "                          'issue_d','last_pymnt_d'],inplace=True) #ALSO, drop date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPEAT DROPS for X_test\n",
    "X_test_all.drop(columns=['term','verification_status', \n",
    "                         'grade','emp_title', 'addr_state',\n",
    "                         #ALSO, drop redundant columns that new OHE columns provide the info for\n",
    "                         'debt_settlement_flag',#ALSO, drop columns clearly not predictive of class\n",
    "                         'issue_d','last_pymnt_d'],inplace=True) #ALSO, drop date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all.set_index('index',inplace=True)\n",
    "X_test_all.set_index('index',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(880950, 1124)\n",
      "(377551, 1124)\n",
      "(880950, 1)\n",
      "(377551, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_all.shape)\n",
    "print(X_test_all.shape)\n",
    "print(y_train_all.shape)\n",
    "print(y_test_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>...</th>\n",
       "      <th>emp_title_2_Technician</th>\n",
       "      <th>emp_title_2_Truck Driver</th>\n",
       "      <th>emp_title_2_Vice President</th>\n",
       "      <th>emp_title_2_driver</th>\n",
       "      <th>emp_title_2_manager</th>\n",
       "      <th>emp_title_2_owner</th>\n",
       "      <th>emp_title_2_sales</th>\n",
       "      <th>emp_title_2_supervisor</th>\n",
       "      <th>emp_title_2_teacher</th>\n",
       "      <th>emp_title_2_truck driver</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>798015</th>\n",
       "      <td>20000</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>24704.737119</td>\n",
       "      <td>0.1239</td>\n",
       "      <td>448.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0</td>\n",
       "      <td>12173.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962964</th>\n",
       "      <td>15000</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>10780.580000</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>505.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>31.05</td>\n",
       "      <td>1</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534392</th>\n",
       "      <td>16000</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>18049.571386</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>502.72</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>18.67</td>\n",
       "      <td>1</td>\n",
       "      <td>9162.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668134</th>\n",
       "      <td>24000</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>27124.598857</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>754.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>21.02</td>\n",
       "      <td>0</td>\n",
       "      <td>10804.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068586</th>\n",
       "      <td>24000</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>26527.946309</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>736.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>14.71</td>\n",
       "      <td>0</td>\n",
       "      <td>10439.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loan_amnt  funded_amnt   total_pymnt  int_rate  installment  \\\n",
       "index                                                                  \n",
       "798015       20000      20000.0  24704.737119    0.1239       448.85   \n",
       "962964       15000      15000.0  10780.580000    0.1299       505.34   \n",
       "534392       16000      16000.0  18049.571386    0.0818       502.72   \n",
       "668134       24000      24000.0  27124.598857    0.0818       754.07   \n",
       "1068586      24000      24000.0  26527.946309    0.0662       736.89   \n",
       "\n",
       "         emp_length  annual_inc    dti  delinq_2yrs  earliest_cr_line  ...  \\\n",
       "index                                                                  ...   \n",
       "798015          1.0     62000.0   4.82            0           12173.0  ...   \n",
       "962964          1.0     55000.0  31.05            1            7882.0  ...   \n",
       "534392          8.0     72000.0  18.67            1            9162.0  ...   \n",
       "668134          1.0     70000.0  21.02            0           10804.0  ...   \n",
       "1068586         1.0    175000.0  14.71            0           10439.0  ...   \n",
       "\n",
       "         emp_title_2_Technician  emp_title_2_Truck Driver  \\\n",
       "index                                                       \n",
       "798015                      0.0                       0.0   \n",
       "962964                      0.0                       0.0   \n",
       "534392                      0.0                       0.0   \n",
       "668134                      0.0                       0.0   \n",
       "1068586                     0.0                       0.0   \n",
       "\n",
       "         emp_title_2_Vice President  emp_title_2_driver  emp_title_2_manager  \\\n",
       "index                                                                          \n",
       "798015                          0.0                 1.0                  0.0   \n",
       "962964                          0.0                 0.0                  0.0   \n",
       "534392                          0.0                 0.0                  0.0   \n",
       "668134                          0.0                 0.0                  0.0   \n",
       "1068586                         0.0                 0.0                  0.0   \n",
       "\n",
       "         emp_title_2_owner  emp_title_2_sales  emp_title_2_supervisor  \\\n",
       "index                                                                   \n",
       "798015                 0.0                0.0                     0.0   \n",
       "962964                 0.0                0.0                     0.0   \n",
       "534392                 0.0                0.0                     0.0   \n",
       "668134                 0.0                0.0                     0.0   \n",
       "1068586                0.0                0.0                     0.0   \n",
       "\n",
       "         emp_title_2_teacher  emp_title_2_truck driver  \n",
       "index                                                   \n",
       "798015                   0.0                       0.0  \n",
       "962964                   0.0                       0.0  \n",
       "534392                   0.0                       0.0  \n",
       "668134                   0.0                       0.0  \n",
       "1068586                  0.0                       0.0  \n",
       "\n",
       "[5 rows x 1124 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaling to Prep for Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train_10pcnt)\n",
    "# X_train_all_scaled = scaler.transform(X_train_all)\n",
    "# X_test_all_scaled = scaler.transform(X_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=0.95, svd_solver='full')\n",
    "# X_train_pca = pca.fit_transform(X_train_10pcnt_scaled)\n",
    "# X_train_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('num_components:', len(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After the above preprocessing, we ended up with 1,124 features. I ran PCA on the dataset with the hope to further reduce feature size. Unfortunately, the 95% variance threshold corresponds to around 972 features, which is close to 95% of the total number of features. After testing a few thresholds, it seems I cannot significantly reduce the feature size without sacrificing variances. \n",
    "- I decided to keep all features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Modeling (Fully Paid = 1, Charged-Off = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all['loan_status'] = y_train_all['loan_status'].astype(int)\n",
    "y_test_all['loan_status'] = y_test_all['loan_status'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jupyter/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=1000, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(class_weight='balanced', solver='lbfgs', max_iter=1000)\n",
    "log_reg.fit(X_train_all,y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_all_preds = log_reg.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Fully Paid: 0.9996676669562242\n",
      "Recall Fully Paid: 0.9994637699276911\n",
      "F-1 Score Fully Paid: 0.9995657080439424\n",
      "ROC-AUC Score: 0.9990455291733132\n"
     ]
    }
   ],
   "source": [
    "print (\"Precision Fully Paid: {}\".format(precision_score(y_test_all,y_test_all_preds)))\n",
    "print (\"Recall Fully Paid: {}\".format(recall_score(y_test_all,y_test_all_preds)))\n",
    "print (\"F-1 Score Fully Paid: {}\".format(f1_score(y_test_all,y_test_all_preds)))\n",
    "print (\"ROC-AUC Score: {}\".format(roc_auc_score(y_test_all,y_test_all_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision, Recall, F, & Support By Class [0,1] aka [Default,Fully Paid]: (array([0.9977865 , 0.99966767]), array([0.99862729, 0.99946377]), array([0.99820672, 0.99956571]), array([ 73577, 303974]))\n",
      "Precision, Recall, F, & Support Weighted Average by Support: (0.9993010656372601, 0.9993007567189598, 0.9993008683031771, None)\n"
     ]
    }
   ],
   "source": [
    "#precision, recall, f1-score\n",
    "print (\"Precision, Recall, F, & Support By Class [0,1] aka [Default,Fully Paid]: {}\".format(\n",
    "    precision_recall_fscore_support(y_test_all,y_test_all_preds)))\n",
    "\n",
    "print (\"Precision, Recall, F, & Support Weighted Average by Support: {}\".format(\n",
    "    precision_recall_fscore_support(y_test_all,y_test_all_preds,average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilize JobLib to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['log_reg_v1.joblib']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to disk\n",
    "filename = 'log_reg_v1.joblib'\n",
    "joblib.dump(log_reg, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick test of JobLib loading of fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test load the model from disk\n",
    "loaded_log_reg_v1 = joblib.load(filename)\n",
    "result = loaded_log_reg_v1.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Fully Paid: 0.9996676669562242\n",
      "Recall Fully Paid: 0.9994637699276911\n",
      "F-1 Score Fully Paid: 0.9995657080439424\n",
      "ROC-AUC Score: 0.9990455291733132\n"
     ]
    }
   ],
   "source": [
    "print (\"Precision Fully Paid: {}\".format(precision_score(y_test_all,result)))\n",
    "print (\"Recall Fully Paid: {}\".format(recall_score(y_test_all,result)))\n",
    "print (\"F-1 Score Fully Paid: {}\".format(f1_score(y_test_all,result)))\n",
    "print (\"ROC-AUC Score: {}\".format(roc_auc_score(y_test_all,result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Model #1: Classification Model to Filter Rows for Model #2: Regression on IRR\n",
    "- I will use my predicted classification from Model #1 on train set to feed to Model #2, rather than filtering using pre-labelled classes\n",
    "- This is what I would need to do with new, real-world data so my training process should mimic this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRR Target Variable Calculation/Extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating NAR\n",
    "lc_df[['total_rec_int','total_rec_late_fee','installment','collection_recovery_fee','out_prncp','loan_status']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_df['last_pymnt_d'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lc_df['last_payment_date'] = lc_df['last_pymnt_d'].str[:3]+'/'+'1'+'/'+lc_df['last_pymnt_d'].str[4:]\n",
    "lc_df['issue_date'] = lc_df['issue_d'].str[:3]+'/'+'1'+'/'+lc_df['issue_d'].str[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_df['last_payment_date'] = lc_df['last_payment_date'].astype(str)\n",
    "lc_df['issue_date'] = lc_df['issue_date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_df = lc_df[lc_df['last_payment_date'] != 'nan'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_df['last_payment_date'][1319]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "lc_df['last_payment_date_dt'] = lc_df['last_payment_date'].map(lambda x: datetime.strptime(x,'%b/%d/%Y'))\n",
    "lc_df['issue_date_dt'] = lc_df['issue_date'].map(lambda x: datetime.strptime(x,'%b/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_df['issue_date_dt'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_df['days_btwn_funding_lastpayment'] = (lc_df['last_payment_date_dt'].dt.date -\n",
    "                                          lc_df['issue_date_dt'].dt.date).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_lc_df['y_stanford'] = (raw_lc_df['total_pymnt']/raw_lc_df['funded_amnt'])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_df[['addr_state','annual_inc','collection_recovery_fee','emp_title',\n",
    "           'fico_range_high','fico_range_low','funded_amnt','grade','home_ownership',\n",
    "           'int_rate','loan_amnt','loan_status','purpose','sub_grade','title','total_rec_int',\n",
    "           'total_rec_late_fee','total_rec_prncp','zip_code','debt_settlement_flag','out_prncp',\n",
    "           'collection_recovery_fee','days_btwn_funding_lastpayment','y_stanford']][lc_df['loan_status'] == 1].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(50): \n",
    "#     if raw_lc_df.loc[i,'loan_status'] != 'Charged Off':\n",
    "#         raw_lc_df.loc[i,'NAR_test'] = ((1+((((raw_lc_df['total_rec_int'][i] #(interest received\n",
    "#                                     +raw_lc_df['total_rec_late_fee'][i] # + late fees received\n",
    "#                                     -(0.01*raw_lc_df['installment'][i]) # - service fee paid\n",
    "#                                     +((raw_lc_df['collection_recovery_fee'][i]/.4)*.6) # + collection fees received\n",
    "#                                     - 0) # - 0 or out.principal\n",
    "#                                  /(raw_lc_df['out_prncp'][i])) #ALL THE ABOVE divided by out.principal\n",
    "#                                     *raw_lc_df['out_prncp'][i]) #FRACTION ABOVE times out.principal\n",
    "#                                  / (raw_lc_df['out_prncp'][i])))**12)-1 #TERM ABOVE divided by out.principal, \n",
    "#                                                                     #& EVERYTHING to the power of 12 & ALL OF THAT minus 1\n",
    "#     else: \n",
    "#         raw_lc_df.loc[i,'NAR_test'] = ((1+((((raw_lc_df['total_rec_int'][i] #(interest received\n",
    "#                                     +raw_lc_df['total_rec_late_fee'][i] # + late fees received\n",
    "#                                     -(0.01*raw_lc_df['installment'][i]) # - service fee paid\n",
    "#                                     +((raw_lc_df['collection_recovery_fee'][i]/.4)*.6) # + collection fees received\n",
    "#                                     - raw_lc_df['out_prncp'][i]) # - 0 or out.principal\n",
    "#                                  /(raw_lc_df['out_prncp'][i])) #ALL THE ABOVE divided by out.principal\n",
    "#                                     *raw_lc_df['out_prncp'][i]) #FRACTION ABOVE times out.principal\n",
    "#                                  / (raw_lc_df['out_prncp'][i])))**12)-1 #TERM ABOVE divided by out.principal, \n",
    "#                                                                     #& EVERYTHING to the power of 12 & ALL OF THAT minus 1\n",
    "#     print('row completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
